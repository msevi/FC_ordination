---
title: "Ordination on FC data"
author: "Maria Sevillano & Solize Vosloo"
date: "17/03/2021"
output:
  rmdformats::readthedown:
    highlight: kate
---

```{r setup, include=FALSE}
library(knitr)
library(rmdformats)

## Global options
options(max.print="75")
opts_chunk$set(cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)
```

## Load libraries
[`PhenoFlow`](https://github.com/rprops/PhenoFlow) is used to process data. The aim of this package is to obtain diversity estimates from FC data. It requires several FC oriented packages such as `flowViz` and `flowCore`, as well as community ecology package `vegan`, see their github `libraries.R` script for package download.  

Alternatively, the `Phenoflow` functions can be sourced from `MRM.parameters.R`, wich have slightly different names and input arguments in some cases.  The Rscript `Fingerprint.R` is also included in this github repository, and was used to guide the FC analyses shown here.

```{r load_libraries, warning=FALSE, message=FALSE}
library(Phenoflow)
source("MRM.parameters.R") 

library(tidyverse) 

library(skimr)
library(GGally)
library(magrittr)

library(factoextra)
```


## Data input

We will input a month worth of environmental and FC data corresponding to water taps from residential (RES) and commercial (COM) buildings.

Note that not all the timepoints for FC data are contained within the environmental database. The environomental data timepoints indicate that the sample was selected for biomass related analyses. 

The total number of initial `.fcs` files was 516.  We have made some data pre selection in the background to reduce the number of files hosted by github. Specifically, we kept 231 files corresponding to total cell count stain and timepoints from 1 to 7. 

**Side note**: naming of files is important. What is good/bad about the file names?  
The following hint can help you when selecting samples in batch from your terminal:  

`ls *.fcs > list_files`  

`grep "TCC_TP0[1-7]" list_files > selected_TCC_list_files`  

`mkdir selected`  

`while read file; do cp "$file" selected; done < selected_TCC_list_files`  


```{r data_in, warning=FALSE, message=FALSE}
flowData <- flowCore::read.flowSet(path = "data/Run001_060420_060520", pattern=".fcs") 
EnvData <- readxl::read_excel("data/sample.database.xlsx", sheet = "Chemical_data") 
```

## Data exploration and wrangling

It's always important to explore the data prior to any analyses (e.g., look at the distribution of the data).

For environmental data, we can look at the structure of the dataframe using base functions. However, there are more sophisticated functions from packages like `skimr` and `GGally` that we can use to obtain additional information quickly. 

To explore FC data, we need to learn about flowSet objects.

Classes in `flowCore`  

* flowFrame - a class representing the data contained in a FCS file.    

(1) raw measurement  
(2) keywords in the FCS files  
(3) annotation for parameters (stains, sample names, range)  
    
* flowSet - a collection of flowFrame.

There are several options to work with a flowSet object, such as:  

* [, [[, $ , @ - subsetting  
* sampleNames, colnames - names  
* phenoData, pData - metadata  
* fsApply - apply family, flowSet-specific iterator  

**Side note**: `%<>%` might be a new operator for you. It's from the `magrittr` package and represents pipe and assign.  

```{r explore, warning=FALSE, message=FALSE }
str(EnvData)

skimr::skim(EnvData)

EnvData %<>%  
  tibble::column_to_rownames("Sample.Id") %>% 
  dplyr::select(Property, ends_with(".R1")) %>% 
  rename_at(vars(ends_with(".R1")), funs(sub(".R1", "",.))) %>% 
  dplyr::select(!ends_with(".carbon")) %>% 
  dplyr::select(-Total.dissolved.nitrogen, -Total.nitrogen) %>% 
  dplyr::rename(DO = "Dissolved.oxygen",
                Chlorine = "Total.chlorine")  

summary(EnvData)

EnvData %<>%  
  tidyr::drop_na() 

GGally::ggpairs(EnvData %>% 
          dplyr::select_if(is.numeric))

EnvData %<>% 
  mutate(Conductivity= case_when(
    rownames(.)=="SW135" ~ 197.70,
    TRUE ~ Conductivity
  ))

###################################################################

class(flowData)
summary(flowData)[1]
head(sampleNames(flowData))
colnames(flowData)
tail(flowCore::pData(flowData)) 
flowData[[1]]
```

## Pre-processing
### Transformations
Environmental data have different units as well as scales, therefore some type of nomalization has to be performed. We will center (subtract variable means from each observation) and scale (multiply each measurement by a scalar factor so that the resulting feature has a variance of one) to ensures equal contribution from each variable.

There's several transformations that can be applied to FC data. In this tutorial, FC data will be transformed by arcsinh, which improves the visualization of data with a low variance and helps data appear more normal by:  

(1) Allowing for negative values to be included  

(2) Providing a linear representation around 0  

(3) Smooth transition of values between extremes  

```{r transformations, warning=FALSE, message=FALSE}
EnvData_transformed<- scale(EnvData %>% 
                              dplyr::select(-Property)) %>% 
  as.data.frame()

GGally::ggpairs(EnvData_transformed)

EnvData_groupings<- EnvData %>% 
  dplyr::select(Property) %>% 
  mutate(category= str_remove(Property, "[:digit:]+"))

###################################################################

flowData_transformed<- flowCore::transform(flowData,
                                            `FL1-H`=asinh(`FL1-H`), 
                                            `SSC-H`=asinh(`SSC-H`), 
                                            `FL3-H`=asinh(`FL3-H`), 
                                            `FSC-H`=asinh(`FSC-H`))
```


### Denoise and gating
Choose features (i.e., channels) and remove instrument/sample noise with `PolygonGate` function. This function will extract observations bounded by the gate as a subset of the full data set. Further all values will be normalized by green fluorescence channel... WHY?

The `flowBasis` function from `flowFDA` calculates the fingerprints.
The resulting class represents a flowset by a basis derived from a kernel density estimator using an equally spaced grid.
 K is the kernel — a non-negative function — and h > 0 is a smoothing parameter called the bandwidth


```{r denoise_gates}
param<- c("FL1-H", "FL3-H","SSC-H","FSC-H")
sqrcut1 <- matrix(c(8.75,8.75,14,14,3,7.5,14,3),ncol=2, nrow=4) # gate coordinates in format: c(x,x,x,x,y,y,y,y) ##how were these coordinate chosen
colnames(sqrcut1) <- c("FL1-H","FL3-H")
polyGate1 <- flowCore::polygonGate(.gate=sqrcut1, filterId = "Total Cells")

# Gating quality check
flowViz::xyplot(`FL3-H` ~ `FL1-H`, 
       data=flowData_transformed[1], 
       filter=polyGate1,
       scales=list(y=list(limits=c(0,14)),
                   x=list(limits=c(6,16))),
       axis = axis.default, nbin=125, 
       par.strip.text=list(col="white", font=2, cex=2), 
       smooth=FALSE)

# Isolate only the cellular information based on the polyGate1
flowData_transformed <- flowCore::Subset(flowData_transformed, polyGate1)
summary <- flowCore::fsApply(x = flowData_transformed, 
                   FUN = function(x) apply(x, 2, max), 
                   use.exprs = TRUE) #for each channel obtain max value

maxval <- max(summary[,"FL1-H"])  #extract max value corresponding to green fluorescent channel
mytrans <- function(x) x/maxval

flowData_transformed <- flowCore::transform(flowData_transformed,
                                  `FL1-H`=mytrans(`FL1-H`),
                                  `FL3-H`=mytrans(`FL3-H`), 
                                  `SSC-H`=mytrans(`SSC-H`),
                                  `FSC-H`=mytrans(`FSC-H`))

fbasis<- flowFDA::flowBasis(flowData_transformed, 
                           param, #channels for which the bivariate density basis are derived
                           nbin=128, #Number of bins that are taken in each channel to approximate the bivariate densities
                           bw=0.01, #Bandwidth of for the kernel density estimator calculated at each bin
                           normalize=function(x) x) # A user defined function for rescaling or normalising the densities, standard the density estimates are rescaled between 0 and 1

```

## PCA

We will perform Principal Component analyses using environmental data. 

How many dimensions should we focus on?  
    *  See scree plot (elbow)  
    *  Kaiser-Guttman criterion: Selects principal components which capture more variance than the average of all PCs

```{r PCA, warning=FALSE, message=FALSE}
res.pca <- prcomp(EnvData_transformed) #we can also use the scale and center arguments here
res.pca2 <- vegan::rda(EnvData_transformed) #another option

res.pca
res.pca2

fviz_eig(res.pca) #scree plot

##Extract eigenvalues
Eigenvalues.pca <- vegan::eigenvals(res.pca) 

Eigenvalues.pca[Eigenvalues.pca>mean(Eigenvalues.pca)] #Kaiser-Guttman

##Variance information
Variance.pca <- Eigenvalues.pca / sum(Eigenvalues.pca) 
Variance.pca.1 <- as.numeric(100 * signif(Variance.pca[1], 4))
Variance.pca.2<- as.numeric(100 * signif(Variance.pca[2], 4)) 
Variance.pca.3<- as.numeric(100 * signif(Variance.pca[3], 4)) 

##Extract loadings (variable coordinates)
loadings.pca <- res.pca$rotation

##Standard deviation information
sdev.pca <- res.pca$sdev

##Coordinates
var_coord_func <- function(loadings, comp.sdev){
  loadings*comp.sdev
}

var.coord.pca <- loadings.pca %>% 
  as_tibble() %>% 
  rowwise() %>% 
  purrr::map2(., sdev.pca, var_coord_func) %>% 
  bind_rows() %>% 
  as.data.frame()
  
rownames(var.coord.pca) <- rownames(loadings.pca)

var.cos.pca <- var.coord.pca^2 #compute Cos2 (the variable components squared), or quality of representation on given dimension
comp.cos.pca <- var.cos.pca %>% 
  summarise_all(sum)

##Contributions
contrib.pca_func <- function(var.cos.pca,comp.cos.pca){var.cos.pca*100/comp.cos.pca}
var.contrib.pca <- var.cos.pca %>% 
  as_tibble() %>% 
  rowwise() %>% 
  purrr::map2(., comp.cos.pca, contrib.pca_func) %>% 
  bind_rows() %>% 
  as.data.frame()

rownames(var.contrib.pca) <- rownames(var.cos.pca)

res.pca.out <- res.pca$x[,c("PC1", "PC2")] %>% 
  as.data.frame() %>% 
  tibble::rownames_to_column("Sample.Id") %>% 
  left_join(EnvData_groupings %>% 
              rownames_to_column("Sample.Id"))
```

### Visualization

We will visualize the PCA as a biplot, where samples are positioned in terms of PC1 and PC2 (i.e., observations) and the initial variables are mapped onto the plot as well. With this type of graphs, you can explore the trends in the data samples and features simultaneously.

Because eigenvalues reflect the variance in coordinates of the associated PCs, you only need to ensure that in the plots, one "unit" in direction of one PC has the same length as one "unit" in direction of another PC. (If you use ggplot2 R package for generating plots, adding + coord_fixed(1) will ensure a correct aspect ratio.)

**Side note**: snippets help you type less! 
```{r PCA_viz}
p <- fviz_pca_biplot(res.pca, 
                     geom="point", 
                     pointsize = 6,
                     habillage=EnvData_groupings$category,
                     invisible = "quali",
                     col.var = "azure4", 
                     alpha =0.7) + 
  scale_color_manual(values=c("grey1","#990000")) + 
  scale_shape_manual(values = c(16,16)) + 
  labs(title = "PCA", subtitle = "ENVIRONMENTAL FACTORS") +
  theme_bw(base_size = 14) +
  theme(plot.title = element_text(face="bold", size=16),
        legend.title = element_text(face="plain", size=14),
        plot.subtitle = element_text(face="bold", size=14,
                                     color="azure4"),
        legend.position = "right") 

#library(usethis)
#usethis::edit_rstudio_snippets()

data_arrow<- loadings.pca %>% 
  as.data.frame() %>% 
  select(PC1, PC2) %>% 
  mutate_all(function(x) x*10) %>%  
  rownames_to_column("variable")

p2 <- ggplot() +
  geom_point(data= res.pca.out, aes(PC1, PC2, color=category), alpha=0.7, size=6) +
  geom_hline(yintercept = 0, linetype = 'dotted') +
  geom_vline(xintercept = 0, linetype = 'dotted') +
  geom_segment(data= data_arrow,
               aes(x = 0, y = 0, xend = PC1, yend = PC2),
               arrow = arrow(length = unit(0.1, "inches")),
               lineend = "round",
               linejoin = "round",
               color= "gray") +
  geom_text(data= data_arrow, 
            aes(x=PC1, y=PC2, label=variable), 
            hjust = 'outside', 
            nudge_x = 0.2,
            color= "gray") +
  xlab(paste0("PC1 (", Variance.pca.1, "%)")) +
  ylab(paste0("PC2 (", Variance.pca.2, "%)")) +
  scale_color_manual(values=c("grey1","#990000")) + 
  scale_shape_manual(values = c(16,16)) + 
  labs(title = "PCA", subtitle = "ENVIRONMENTAL FACTORS") +
  theme_bw(base_size = 14) +
  theme(plot.title = element_text(face="bold", size=16),
  legend.title = element_text(face="plain", size=14),
  plot.subtitle = element_text(face="bold", size=14, 
  color="azure4"),
  legend.position = "right") +
  coord_fixed(1)
  
p 

p2
```

## PCoA

The PCoA for FC data preserves Bray-Curtis distances and results from a matrix of features corresponding to the previously chosen parameters (i.e., "FL1-H", "FL3-H","SSC-H","FSC-H").  

The matrix of parameters can be extracted from `fbasis@basis` 

```{r PCoA}
flowDataBD <- beta.div.fcm(fbasis,
                           n=1,
                           ord.type="PCoA") # sourced function, based on Bray-Curtis distances, unsing cmdscale

str(flowDataBD)


flowDataBD_PCApoints <- flowDataBD %>% 
  purrr::simplify() %>% 
  dplyr::first() %>% 
  as.data.frame() %>% 
  tibble::rownames_to_column("fcs.id") %>% 
  rename(PC1 = "V1",
         PC2 = "V2") %>% 
  tidyr::separate(fcs.id, into = c("Well","col01"),sep=" ") %>%
  tidyr::separate(col01, into = c("Location","Stain","TimePoint","Replicate"),sep="_") %>%
  tidyr::separate(Replicate, into = c("replicate","col06"),sep=".fcs") %>% 
  select(-col06) %>% 
  mutate(Site= case_when(
    grepl("COM", Location) ~ "Commercial",
    TRUE ~ "Residential"
  )) %>%
  dplyr::filter(Stain == "TCC") %>%
  dplyr::filter(TimePoint %in% c("TP01","TP02","TP03","TP04","TP05","TP06","TP07"))
  
```

### Visualization

```{r PCA_plot}
p3<- ggplot(flowDataBD_PCApoints, aes(x = PC1, y = PC2)) + 
  geom_point(size = 4, aes(colour = Site), alpha =0.7)+
  theme_bw(base_size = 14) +
  theme(plot.title = element_text(face="bold", size=16),legend.title = element_text(face="plain", size=14),plot.subtitle = element_text(face="bold", size=14, color="azure4"),legend.position = "right") + 
  labs(x = "PC1", colour = "Site", y = "PC2", title = "PCoA", subtitle = "COMMERCIAL & RESIDENTIAL LOCATIONS")  + 
  scale_color_manual(values=c("grey1","#990000")) + 
  coord_fixed(1)

p3
```

